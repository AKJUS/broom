<!--
%\VignetteBuilder{knitr::knitr}
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Tidy bootstrapping with dplyr+broom}
-->

```{r setup, echo=FALSE}
library(knitr)
opts_chunk$set(message=FALSE)
```

Tidy bootstrapping with dplyr+broom
===================================

Another place where combining model fits in a tidy way becomes useful is when performing bootstrapping or permutation tests. These approaches have been explored before, for instance by [Andrew MacDonald here](http://rstudio-pubs-static.s3.amazonaws.com/19698_a4c472606e3c43e4b94720506e49bb7b.html), and [Hadley has explored efficient support for bootstrapping](https://github.com/hadley/dplyr/issues/269) as a potential enhancement to dplyr. broom fits naturally with dplyr in performing these analyses.

Bootstrapping consists of randomly sampling a dataset with replacement, then performing the analysis individually on each bootstrapped replicate. The variation in the resulting estimate is then a reasonable approximation of the variance in your estimate. Permutation tests . This provides a distribution of null statistics, which can be compared to the test statistic to compute a p-value.

Let's say you want to fit a nonlinear model to the weight/mileage relationship in the `mtcars` dataset.

```{r}
library(ggplot2)
data(mtcars)
ggplot(mtcars, aes(mpg, wt)) + geom_point()
```

You might use the method of nonlinear least squares (`nls` function) to fit a model.

```{r}
nlsfit <- nls(mpg ~ k / wt + b, mtcars, start=list(k=1, b=0))
summary(nlsfit)
ggplot(mtcars, aes(wt, mpg)) + geom_point() + geom_line(aes(y=predict(nlsfit)))
```

While this does provide a p-value and confidence intervals for the parameters, these are based on model assumptions that may not hold in real data. Bootstrapping is a popular method for providing confidence intervals and predictions that are more robust to the nature of the data.

First, we construct 100 bootstrap replications of the data, each of which has been randomly sampled with replacement[^efficiency]:

```{r}
library(dplyr)
set.seed(2014)
bootreps <- data.frame(replication=1:100) %>% group_by(replication) %>%
    do(sample_n(mtcars, nrow(mtcars), replace=TRUE))
```

Since the `bootreps` data frame is grouped by replication, you can perform your `nls` fit on each of them, then use `tidy` to recombine:

```{r}
library(broom)
bootnls <- bootreps %>% do(tidy(nls(mpg ~ k / wt + b, ., start=list(k=1, b=0))))
bootnls
```

You can then calculate confidence intervals (using what is called the [percentile method](http://www.uvm.edu/~dhowell/StatPages/Resampling/BootstMeans/bootstrapping_means.html)[^percentile]):

```{r}
alpha = .05
bootnls %>% group_by(term) %>% summarize(low=quantile(estimate, alpha / 2),
                                         high=quantile(estimate, 1 - alpha / 2))
```

Or you can use histograms to give you a more detailed idea of the uncertainty in each estimate:

```{r}
library(ggplot2)
ggplot(bootnls, aes(estimate)) + geom_histogram(binwidth=2) + facet_wrap(~ term, scales="free")
```

With only a few small changes, one could easily perform bootstrapping with other kinds of predictive or hypothesis testing models, since the `tidy` function works for many stats outputs.

[^efficiency]: Hadley's approach [here](https://github.com/hadley/dplyr/issues/269) is considerably more efficient in memory than this one, especially when the data or number of replications is large, but as noted in [my StackOverflow query here](http://stackoverflow.com/questions/25793383/using-dplyrs-do-to-perform-bootstrap-replications) it doesn't work for `do`. If the issue is solved or the functionality added to `dplyr`, I will certainly update this vignette. The downstream steps using broom remain identical either way.
[^percentile]: This is the simplest of many ways to calculate a bootstrap confidence interval, but other methods lend themselves equally well to the tidy approach.